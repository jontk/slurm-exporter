version: '3.8'

services:
  # SLURM Controller with REST API
  slurm-controller:
    image: slurm-docker/slurm:latest
    hostname: slurm-controller
    container_name: slurm-controller
    privileged: true
    volumes:
      - slurm-state:/var/lib/slurm-llnl
      - slurm-logs:/var/log/slurm-llnl
      - ./slurm-configs:/etc/slurm-llnl
    ports:
      - "6820:6820"  # SLURM REST API
      - "6817:6817"  # SLURM Controller
    environment:
      - SLURM_CONF=/etc/slurm-llnl/slurm.conf
      - SLURM_USER=slurm
    command: >
      sh -c "
        # Start SLURM controller daemon
        slurmd -D &
        slurmctld -D &
        
        # Start REST API daemon
        slurmrestd -vvv -a rest_auth/jwt 0.0.0.0:6820 &
        
        # Keep container running
        sleep infinity
      "
    healthcheck:
      test: ["CMD", "scontrol", "ping"]
      interval: 30s
      timeout: 10s
      retries: 3

  # SLURM Compute Node Simulator
  slurm-node:
    image: slurm-docker/slurm:latest
    hostname: slurm-node-001
    container_name: slurm-node-001
    privileged: true
    depends_on:
      - slurm-controller
    volumes:
      - slurm-state:/var/lib/slurm-llnl
      - slurm-logs:/var/log/slurm-llnl
      - ./slurm-configs:/etc/slurm-llnl
    environment:
      - SLURM_CONF=/etc/slurm-llnl/slurm.conf
      - SLURM_USER=slurm
    command: >
      sh -c "
        # Wait for controller
        sleep 30
        
        # Start compute node daemon
        slurmd -D -N slurm-node-001
      "

  # Job Generator (creates sample workload)
  job-generator:
    image: slurm-docker/slurm:latest
    container_name: job-generator
    depends_on:
      - slurm-controller
    volumes:
      - ./slurm-configs:/etc/slurm-llnl
      - ./sample-jobs:/opt/jobs
    environment:
      - SLURM_CONF=/etc/slurm-llnl/slurm.conf
    command: >
      sh -c "
        # Wait for SLURM to be ready
        sleep 60
        
        # Submit sample jobs continuously
        while true; do
          # Short jobs
          sbatch --wrap='sleep $((RANDOM % 300 + 60))' --job-name=short-job --time=10:00
          
          # Medium jobs  
          sbatch --wrap='sleep $((RANDOM % 1800 + 300))' --job-name=medium-job --time=1:00:00 --cpus-per-task=2
          
          # Long jobs
          sbatch --wrap='sleep $((RANDOM % 7200 + 1800))' --job-name=long-job --time=4:00:00 --cpus-per-task=4 --mem=4G
          
          # GPU jobs (simulated)
          sbatch --wrap='sleep $((RANDOM % 3600 + 600))' --job-name=gpu-job --time=2:00:00 --gres=gpu:1
          
          # Failed jobs (for testing)
          if [ $((RANDOM % 10)) -eq 0 ]; then
            sbatch --wrap='exit 1' --job-name=failing-job --time=5:00
          fi
          
          # Random wait between submissions
          sleep $((RANDOM % 120 + 30))
        done
      "

  # SLURM Exporter
  slurm-exporter:
    image: ghcr.io/jontk/slurm-exporter:latest
    container_name: slurm-exporter
    depends_on:
      - slurm-controller
    ports:
      - "8080:8080"
    volumes:
      - ./sandbox-config.yaml:/etc/slurm-exporter/config.yaml
    environment:
      - CONFIG_FILE=/etc/slurm-exporter/config.yaml
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Prometheus
  prometheus:
    image: prom/prometheus:latest
    container_name: prometheus
    ports:
      - "9090:9090"
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml
      - ./alert-rules.yml:/etc/prometheus/alert-rules.yml
      - prometheus-data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
      - '--storage.tsdb.retention.time=7d'
      - '--web.enable-lifecycle'
    depends_on:
      - slurm-exporter

  # Alertmanager
  alertmanager:
    image: prom/alertmanager:latest
    container_name: alertmanager
    ports:
      - "9093:9093"
    volumes:
      - ./alertmanager.yml:/etc/alertmanager/alertmanager.yml
      - alertmanager-data:/alertmanager
    command:
      - '--config.file=/etc/alertmanager/alertmanager.yml'
      - '--storage.path=/alertmanager'
      - '--web.external-url=http://localhost:9093'

  # Grafana
  grafana:
    image: grafana/grafana:latest
    container_name: grafana
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin
      - GF_USERS_ALLOW_SIGN_UP=false
      - GF_INSTALL_PLUGINS=grafana-piechart-panel
    volumes:
      - grafana-data:/var/lib/grafana
      - ./grafana/provisioning:/etc/grafana/provisioning
      - ./grafana/dashboards:/var/lib/grafana/dashboards
    depends_on:
      - prometheus

  # Node Exporter (for system metrics)
  node-exporter:
    image: prom/node-exporter:latest
    container_name: node-exporter
    ports:
      - "9100:9100"
    command:
      - '--path.rootfs=/host'
    volumes:
      - '/:/host:ro,rslave'

  # Tutorial Web Server
  tutorial-server:
    image: nginx:alpine
    container_name: tutorial-server
    ports:
      - "8888:80"
    volumes:
      - ./web:/usr/share/nginx/html
      - ./web/nginx.conf:/etc/nginx/nginx.conf
    depends_on:
      - grafana
      - prometheus
      - slurm-exporter

volumes:
  slurm-state:
  slurm-logs:
  prometheus-data:
  alertmanager-data:
  grafana-data:

networks:
  default:
    name: slurm-sandbox