# Performance Benchmarking Framework for SLURM Exporter
# This file defines comprehensive benchmarking and performance regression testing

apiVersion: v1
kind: ConfigMap
metadata:
  name: benchmark-config
  namespace: slurm-exporter
  labels:
    app: slurm-exporter
    component: performance-benchmarking
data:
  benchmark-suite.yaml: |
    # Benchmarking Suite Configuration
    benchmarking:
      # Benchmark categories
      categories:
        memory:
          name: "Memory Performance Benchmarks"
          tests:
            - "memory_allocation"
            - "gc_pressure"
            - "memory_leak_detection"
            - "heap_utilization"
            
        cpu:
          name: "CPU Performance Benchmarks"
          tests:
            - "metric_processing"
            - "json_parsing"
            - "regex_matching"
            - "concurrent_collection"
            
        network:
          name: "Network Performance Benchmarks"
          tests:
            - "slurm_api_latency"
            - "http_throughput"
            - "connection_pooling"
            - "concurrent_requests"
            
        storage:
          name: "Storage Performance Benchmarks"
          tests:
            - "config_loading"
            - "log_writing"
            - "cache_performance"
            - "disk_io"
            
        scalability:
          name: "Scalability Benchmarks"
          tests:
            - "large_cluster_simulation"
            - "high_cardinality_metrics"
            - "concurrent_scrapers"
            - "memory_under_load"
      
      # Performance baselines
      baselines:
        memory_allocation:
          metric: "allocations_per_second"
          baseline: 10000
          tolerance: 10
          unit: "allocs/sec"
          
        metric_processing:
          metric: "metrics_processed_per_second"
          baseline: 1000
          tolerance: 15
          unit: "metrics/sec"
          
        slurm_api_latency:
          metric: "api_response_time_p95"
          baseline: 100
          tolerance: 20
          unit: "ms"
          
        gc_pressure:
          metric: "gc_pause_time_p99"
          baseline: 10
          tolerance: 25
          unit: "ms"
      
      # Regression detection
      regression:
        enabled: true
        threshold: 20  # % degradation to trigger alert
        comparison_periods: 
          - "last_week"
          - "last_month"
          - "baseline"
        notification: true

---
apiVersion: batch/v1
kind: Job
metadata:
  name: benchmark-memory
  namespace: slurm-exporter
  labels:
    app: slurm-exporter
    component: performance-benchmarking
    benchmark-type: memory
spec:
  template:
    metadata:
      labels:
        app: slurm-exporter
        component: performance-benchmarking
        benchmark-type: memory
    spec:
      restartPolicy: Never
      
      containers:
      - name: memory-benchmark
        image: golang:1.21
        imagePullPolicy: IfNotPresent
        
        env:
        - name: BENCHMARK_TYPE
          value: "memory"
        - name: RESULTS_BUCKET
          value: "slurm-exporter-benchmark-results"
        
        command:
        - /bin/bash
        - -c
        - |
          set -e
          
          echo "Starting memory performance benchmarks"
          
          # Create benchmark test program
          mkdir -p /tmp/benchmark
          cd /tmp/benchmark
          
          # Initialize Go module
          cat > go.mod << 'EOF'
          module benchmark
          
          go 1.21
          
          require (
            github.com/prometheus/client_golang v1.17.0
            github.com/stretchr/testify v1.8.4
          )
          EOF
          
          # Create memory benchmark tests
          cat > memory_benchmark_test.go << 'EOF'
          package main
          
          import (
            "encoding/json"
            "fmt"
            "runtime"
            "testing"
            "time"
          )
          
          // Simulate metric data structure
          type MetricData struct {
            Name      string            `json:"name"`
            Value     float64           `json:"value"`
            Labels    map[string]string `json:"labels"`
            Timestamp time.Time         `json:"timestamp"`
          }
          
          // BenchmarkMemoryAllocation tests memory allocation performance
          func BenchmarkMemoryAllocation(b *testing.B) {
            b.ReportAllocs()
            
            for i := 0; i < b.N; i++ {
              metrics := make([]MetricData, 1000)
              for j := 0; j < 1000; j++ {
                metrics[j] = MetricData{
                  Name:      fmt.Sprintf("metric_%d", j),
                  Value:     float64(j),
                  Labels:    map[string]string{"job": "test", "instance": "localhost"},
                  Timestamp: time.Now(),
                }
              }
              _ = metrics // Use the metrics to prevent optimization
            }
          }
          
          // BenchmarkJSONSerialization tests JSON processing performance
          func BenchmarkJSONSerialization(b *testing.B) {
            b.ReportAllocs()
            
            // Create test data
            testData := make([]MetricData, 1000)
            for i := 0; i < 1000; i++ {
              testData[i] = MetricData{
                Name:      fmt.Sprintf("slurm_job_state_%d", i),
                Value:     float64(i % 5),
                Labels:    map[string]string{
                  "job_id":    fmt.Sprintf("%d", i),
                  "user":      fmt.Sprintf("user_%d", i%10),
                  "partition": fmt.Sprintf("partition_%d", i%3),
                },
                Timestamp: time.Now(),
              }
            }
            
            b.ResetTimer()
            
            for i := 0; i < b.N; i++ {
              data, err := json.Marshal(testData)
              if err != nil {
                b.Fatal(err)
              }
              
              var unmarshaled []MetricData
              err = json.Unmarshal(data, &unmarshaled)
              if err != nil {
                b.Fatal(err)
              }
            }
          }
          
          // BenchmarkGCPressure tests garbage collection impact
          func BenchmarkGCPressure(b *testing.B) {
            b.ReportAllocs()
            
            // Force GC before starting
            runtime.GC()
            
            var memStats runtime.MemStats
            runtime.ReadMemStats(&memStats)
            startGCTime := memStats.PauseTotalNs
            
            b.ResetTimer()
            
            for i := 0; i < b.N; i++ {
              // Allocate and discard memory to create GC pressure
              data := make([][]MetricData, 100)
              for j := 0; j < 100; j++ {
                data[j] = make([]MetricData, 100)
                for k := 0; k < 100; k++ {
                  data[j][k] = MetricData{
                    Name:   fmt.Sprintf("metric_%d_%d", j, k),
                    Value:  float64(k),
                    Labels: map[string]string{"test": "gc_pressure"},
                  }
                }
              }
              
              // Force GC every 10 iterations
              if i%10 == 0 {
                runtime.GC()
              }
            }
            
            b.StopTimer()
            
            runtime.ReadMemStats(&memStats)
            gcTime := memStats.PauseTotalNs - startGCTime
            b.ReportMetric(float64(gcTime)/float64(b.N), "ns/gc")
          }
          
          // BenchmarkConcurrentAccess tests concurrent memory access
          func BenchmarkConcurrentAccess(b *testing.B) {
            b.ReportAllocs()
            
            sharedData := make(map[string]MetricData, 10000)
            
            // Pre-populate data
            for i := 0; i < 10000; i++ {
              key := fmt.Sprintf("metric_%d", i)
              sharedData[key] = MetricData{
                Name:  key,
                Value: float64(i),
                Labels: map[string]string{"shared": "true"},
              }
            }
            
            b.ResetTimer()
            
            b.RunParallel(func(pb *testing.PB) {
              for pb.Next() {
                // Simulate concurrent read/write operations
                for i := 0; i < 100; i++ {
                  key := fmt.Sprintf("metric_%d", i)
                  if data, exists := sharedData[key]; exists {
                    // Simulate processing
                    _ = data.Value * 2
                  }
                }
              }
            })
          }
          EOF
          
          # Download dependencies
          go mod tidy
          
          # Run memory benchmarks
          echo "Running memory benchmarks..."
          go test -bench=BenchmarkMemory -benchmem -count=3 -timeout=30m > /tmp/memory-results.txt
          
          # Parse results and create summary
          echo "Parsing benchmark results..."
          
          cat > parse_results.go << 'EOF'
          package main
          
          import (
            "bufio"
            "encoding/json"
            "fmt"
            "os"
            "regexp"
            "strconv"
            "strings"
            "time"
          )
          
          type BenchmarkResult struct {
            Name         string  `json:"name"`
            Iterations   int64   `json:"iterations"`
            NsPerOp      float64 `json:"ns_per_op"`
            AllocsPerOp  int64   `json:"allocs_per_op"`
            BytesPerOp   int64   `json:"bytes_per_op"`
            MBPerSec     float64 `json:"mb_per_sec,omitempty"`
          }
          
          type BenchmarkSummary struct {
            Timestamp time.Time          `json:"timestamp"`
            Type      string            `json:"type"`
            Results   []BenchmarkResult `json:"results"`
            Summary   map[string]interface{} `json:"summary"`
          }
          
          func main() {
            file, err := os.Open("/tmp/memory-results.txt")
            if err != nil {
              panic(err)
            }
            defer file.Close()
            
            var results []BenchmarkResult
            scanner := bufio.NewScanner(file)
            
            benchmarkRegex := regexp.MustCompile(`^(Benchmark\w+)(?:-\d+)?\s+(\d+)\s+([\d.]+)\s+ns/op\s+(\d+)\s+B/op\s+(\d+)\s+allocs/op`)
            
            for scanner.Scan() {
              line := scanner.Text()
              matches := benchmarkRegex.FindStringSubmatch(line)
              
              if len(matches) == 6 {
                iterations, _ := strconv.ParseInt(matches[2], 10, 64)
                nsPerOp, _ := strconv.ParseFloat(matches[3], 64)
                bytesPerOp, _ := strconv.ParseInt(matches[4], 10, 64)
                allocsPerOp, _ := strconv.ParseInt(matches[5], 10, 64)
                
                result := BenchmarkResult{
                  Name:        matches[1],
                  Iterations:  iterations,
                  NsPerOp:     nsPerOp,
                  AllocsPerOp: allocsPerOp,
                  BytesPerOp:  bytesPerOp,
                }
                
                results = append(results, result)
              }
            }
            
            // Calculate summary statistics
            summary := map[string]interface{}{
              "total_benchmarks": len(results),
              "avg_ns_per_op":   calculateAverage(results, "ns_per_op"),
              "avg_allocs_per_op": calculateAverage(results, "allocs_per_op"),
              "avg_bytes_per_op":  calculateAverage(results, "bytes_per_op"),
            }
            
            benchmarkSummary := BenchmarkSummary{
              Timestamp: time.Now(),
              Type:      "memory",
              Results:   results,
              Summary:   summary,
            }
            
            // Output JSON
            jsonData, err := json.MarshalIndent(benchmarkSummary, "", "  ")
            if err != nil {
              panic(err)
            }
            
            fmt.Println(string(jsonData))
            
            // Save to file
            err = os.WriteFile("/tmp/memory-benchmark-summary.json", jsonData, 0644)
            if err != nil {
              panic(err)
            }
          }
          
          func calculateAverage(results []BenchmarkResult, field string) float64 {
            if len(results) == 0 {
              return 0
            }
            
            var sum float64
            for _, result := range results {
              switch field {
              case "ns_per_op":
                sum += result.NsPerOp
              case "allocs_per_op":
                sum += float64(result.AllocsPerOp)
              case "bytes_per_op":
                sum += float64(result.BytesPerOp)
              }
            }
            
            return sum / float64(len(results))
          }
          EOF
          
          # Parse and summarize results
          go run parse_results.go
          
          echo "Memory benchmark completed successfully"
          cat /tmp/memory-benchmark-summary.json
        
        resources:
          requests:
            cpu: 500m
            memory: 512Mi
          limits:
            cpu: 2000m
            memory: 2Gi

---
apiVersion: batch/v1
kind: Job
metadata:
  name: benchmark-scalability
  namespace: slurm-exporter
  labels:
    app: slurm-exporter
    component: performance-benchmarking
    benchmark-type: scalability
spec:
  template:
    metadata:
      labels:
        app: slurm-exporter
        component: performance-benchmarking
        benchmark-type: scalability
    spec:
      restartPolicy: Never
      
      containers:
      - name: scalability-benchmark
        image: golang:1.21
        imagePullPolicy: IfNotPresent
        
        env:
        - name: BENCHMARK_TYPE
          value: "scalability"
        - name: TARGET_URL
          value: "http://slurm-exporter.slurm-exporter:10341"
        
        command:
        - /bin/bash
        - -c
        - |
          set -e
          
          echo "Starting scalability benchmarks"
          
          mkdir -p /tmp/scalability
          cd /tmp/scalability
          
          # Create scalability test program
          cat > go.mod << 'EOF'
          module scalability
          
          go 1.21
          
          require (
            github.com/prometheus/client_golang v1.17.0
          )
          EOF
          
          cat > scalability_test.go << 'EOF'
          package main
          
          import (
            "context"
            "fmt"
            "net/http"
            "sync"
            "testing"
            "time"
          )
          
          const baseURL = "http://slurm-exporter.slurm-exporter:10341"
          
          // BenchmarkConcurrentRequests tests concurrent request handling
          func BenchmarkConcurrentRequests(b *testing.B) {
            client := &http.Client{Timeout: 30 * time.Second}
            
            b.ResetTimer()
            
            b.RunParallel(func(pb *testing.PB) {
              for pb.Next() {
                resp, err := client.Get(baseURL + "/metrics")
                if err != nil {
                  b.Errorf("Request failed: %v", err)
                  continue
                }
                resp.Body.Close()
                
                if resp.StatusCode != http.StatusOK {
                  b.Errorf("Expected 200, got %d", resp.StatusCode)
                }
              }
            })
          }
          
          // BenchmarkHighCardinality simulates high cardinality metric collection
          func BenchmarkHighCardinality(b *testing.B) {
            // Simulate processing high cardinality metrics
            for i := 0; i < b.N; i++ {
              metrics := make(map[string]float64, 10000)
              
              // Simulate 10,000 unique metrics
              for j := 0; j < 10000; j++ {
                key := fmt.Sprintf("slurm_job_state{job_id=\"%d\",user=\"user_%d\",partition=\"part_%d\"}", 
                  j, j%100, j%10)
                metrics[key] = float64(j % 5)
              }
              
              // Simulate metric processing
              processedCount := 0
              for _, value := range metrics {
                if value > 0 {
                  processedCount++
                }
              }
              
              if processedCount == 0 {
                b.Error("No metrics processed")
              }
            }
          }
          
          // BenchmarkScalingNodes tests performance with increasing node counts
          func BenchmarkScalingNodes(b *testing.B) {
            nodeCounts := []int{100, 500, 1000, 5000, 10000}
            
            for _, nodeCount := range nodeCounts {
              b.Run(fmt.Sprintf("nodes_%d", nodeCount), func(b *testing.B) {
                b.ReportAllocs()
                
                for i := 0; i < b.N; i++ {
                  // Simulate node metric collection
                  nodeMetrics := make(map[string]map[string]float64, nodeCount)
                  
                  for j := 0; j < nodeCount; j++ {
                    nodeName := fmt.Sprintf("node%d", j)
                    nodeMetrics[nodeName] = map[string]float64{
                      "cpu_usage":    float64((j * 17) % 100),
                      "memory_usage": float64((j * 23) % 100),
                      "disk_usage":   float64((j * 31) % 100),
                      "network_rx":   float64(j * 1024),
                      "network_tx":   float64(j * 512),
                    }
                  }
                  
                  // Simulate metric aggregation
                  totalCPU := 0.0
                  for _, metrics := range nodeMetrics {
                    totalCPU += metrics["cpu_usage"]
                  }
                  
                  avgCPU := totalCPU / float64(nodeCount)
                  if avgCPU < 0 {
                    b.Error("Invalid CPU calculation")
                  }
                }
              })
            }
          }
          
          // BenchmarkConcurrentCollectors tests multiple concurrent collectors
          func BenchmarkConcurrentCollectors(b *testing.B) {
            b.ReportAllocs()
            
            for i := 0; i < b.N; i++ {
              var wg sync.WaitGroup
              
              // Simulate 5 concurrent collectors
              for j := 0; j < 5; j++ {
                wg.Add(1)
                go func(collectorID int) {
                  defer wg.Done()
                  
                  // Simulate collector work
                  ctx, cancel := context.WithTimeout(context.Background(), 5*time.Second)
                  defer cancel()
                  
                  metrics := make([]map[string]interface{}, 1000)
                  for k := 0; k < 1000; k++ {
                    select {
                    case <-ctx.Done():
                      return
                    default:
                      metrics[k] = map[string]interface{}{
                        "collector_id": collectorID,
                        "metric_id":    k,
                        "value":        float64(k),
                        "timestamp":    time.Now().Unix(),
                      }
                    }
                  }
                }(j)
              }
              
              wg.Wait()
            }
          }
          EOF
          
          # Download dependencies and run benchmarks
          go mod tidy
          
          echo "Running scalability benchmarks..."
          go test -bench=. -benchmem -timeout=30m > /tmp/scalability-results.txt
          
          echo "Scalability benchmark results:"
          cat /tmp/scalability-results.txt
          
          echo "Scalability benchmark completed"
        
        resources:
          requests:
            cpu: 1000m
            memory: 1Gi
          limits:
            cpu: 4000m
            memory: 4Gi

---
apiVersion: batch/v1
kind: CronJob
metadata:
  name: performance-regression-detection
  namespace: slurm-exporter
  labels:
    app: slurm-exporter
    component: performance-benchmarking
spec:
  schedule: "0 2 * * 1"  # Weekly on Monday at 2 AM
  concurrencyPolicy: Forbid
  successfulJobsHistoryLimit: 3
  failedJobsHistoryLimit: 3
  jobTemplate:
    spec:
      template:
        metadata:
          labels:
            app: slurm-exporter
            component: performance-benchmarking
            benchmark-type: regression
        spec:
          restartPolicy: Never
          
          containers:
          - name: regression-detector
            image: python:3.11-slim
            imagePullPolicy: IfNotPresent
            
            env:
            - name: PROMETHEUS_URL
              value: "http://prometheus.monitoring:9090"
            - name: SLACK_WEBHOOK
              valueFrom:
                secretKeyRef:
                  name: performance-notifications
                  key: slack-webhook
            
            command:
            - /bin/bash
            - -c
            - |
              set -e
              
              echo "Starting performance regression detection"
              
              # Install required packages
              pip install requests pandas numpy
              
              # Create regression detection script
              cat > /tmp/regression_detector.py << 'EOF'
              import requests
              import json
              import pandas as pd
              import numpy as np
              from datetime import datetime, timedelta
              import os
              
              class PerformanceRegressionDetector:
                  def __init__(self, prometheus_url, slack_webhook):
                      self.prometheus_url = prometheus_url
                      self.slack_webhook = slack_webhook
                      self.regression_threshold = 20  # 20% degradation threshold
                  
                  def query_prometheus(self, query, start_time, end_time):
                      """Query Prometheus for time series data"""
                      params = {
                          'query': query,
                          'start': start_time.isoformat() + 'Z',
                          'end': end_time.isoformat() + 'Z',
                          'step': '300s'  # 5-minute intervals
                      }
                      
                      response = requests.get(
                          f"{self.prometheus_url}/api/v1/query_range",
                          params=params
                      )
                      
                      if response.status_code == 200:
                          return response.json()['data']['result']
                      else:
                          print(f"Failed to query Prometheus: {response.status_code}")
                          return []
                  
                  def analyze_metric(self, metric_name, query):
                      """Analyze a specific metric for regression"""
                      now = datetime.now()
                      
                      # Compare current week vs last week
                      current_week_start = now - timedelta(days=7)
                      current_week_end = now
                      
                      previous_week_start = now - timedelta(days=14)
                      previous_week_end = now - timedelta(days=7)
                      
                      # Get data for both periods
                      current_data = self.query_prometheus(query, current_week_start, current_week_end)
                      previous_data = self.query_prometheus(query, previous_week_start, previous_week_end)
                      
                      if not current_data or not previous_data:
                          print(f"Insufficient data for {metric_name}")
                          return None
                      
                      # Calculate averages
                      current_avg = self.calculate_average(current_data)
                      previous_avg = self.calculate_average(previous_data)
                      
                      if previous_avg == 0:
                          return None
                      
                      # Calculate percentage change
                      change_percent = ((current_avg - previous_avg) / previous_avg) * 100
                      
                      result = {
                          'metric_name': metric_name,
                          'current_avg': current_avg,
                          'previous_avg': previous_avg,
                          'change_percent': change_percent,
                          'is_regression': change_percent > self.regression_threshold
                      }
                      
                      return result
                  
                  def calculate_average(self, data):
                      """Calculate average from Prometheus time series data"""
                      if not data or not data[0].get('values'):
                          return 0
                      
                      values = [float(value[1]) for value in data[0]['values']]
                      return np.mean(values)
                  
                  def send_notification(self, message, status="info"):
                      """Send Slack notification"""
                      emoji = ":warning:" if status == "warning" else ":information_source:"
                      color = "warning" if status == "warning" else "good"
                      
                      payload = {
                          "attachments": [{
                              "color": color,
                              "text": f"{emoji} SLURM Exporter Performance Regression Detection\n{message}"
                          }]
                      }
                      
                      try:
                          requests.post(self.slack_webhook, json=payload)
                      except Exception as e:
                          print(f"Failed to send notification: {e}")
                  
                  def run_analysis(self):
                      """Run complete regression analysis"""
                      print("Running performance regression analysis...")
                      
                      # Define metrics to monitor
                      metrics_to_check = {
                          'Response Time P95': 'histogram_quantile(0.95, rate(slurm_exporter_scrape_duration_seconds_bucket[5m]))',
                          'Error Rate': 'rate(slurm_exporter_collection_errors_total[5m])',
                          'Memory Usage': 'process_resident_memory_bytes{job="slurm-exporter"}',
                          'CPU Usage': 'rate(process_cpu_seconds_total{job="slurm-exporter"}[5m])',
                          'GC Duration': 'rate(go_gc_duration_seconds_sum{job="slurm-exporter"}[5m])',
                      }
                      
                      regressions_found = []
                      
                      for metric_name, query in metrics_to_check.items():
                          print(f"Analyzing {metric_name}...")
                          result = self.analyze_metric(metric_name, query)
                          
                          if result and result['is_regression']:
                              regressions_found.append(result)
                              print(f"REGRESSION DETECTED: {metric_name}")
                              print(f"  Previous: {result['previous_avg']:.2f}")
                              print(f"  Current: {result['current_avg']:.2f}")
                              print(f"  Change: {result['change_percent']:.1f}%")
                      
                      # Send notifications
                      if regressions_found:
                          message = "Performance regressions detected:\n"
                          for regression in regressions_found:
                              message += f"â€¢ {regression['metric_name']}: {regression['change_percent']:.1f}% degradation\n"
                          
                          self.send_notification(message, "warning")
                          print("Regression alert sent")
                          return False
                      else:
                          self.send_notification("No performance regressions detected in weekly analysis", "info")
                          print("No regressions found")
                          return True
              
              if __name__ == "__main__":
                  prometheus_url = os.getenv('PROMETHEUS_URL', 'http://prometheus.monitoring:9090')
                  slack_webhook = os.getenv('SLACK_WEBHOOK')
                  
                  detector = PerformanceRegressionDetector(prometheus_url, slack_webhook)
                  success = detector.run_analysis()
                  
                  if not success:
                      exit(1)
              EOF
              
              # Run regression detection
              python /tmp/regression_detector.py
              
              echo "Performance regression detection completed"
            
            resources:
              requests:
                cpu: 200m
                memory: 256Mi
              limits:
                cpu: 1000m
                memory: 1Gi